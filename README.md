# Domain-Specific Tokenization (DST)

A unified framework for building, analyzing, and validating
**domain-specific tokenizers** with formal consistency guarantees.

> "A tokenizer should not break statistical consistency â€”
> Ï„âˆ˜Îº = Id should hold in practice as well as in theory."

---

## ğŸŒ Supported Domains

- HTTP / Web Requests  (`HTTPTokenizer`)
- HTML / XML Structures (`HTMLTokenizer`)
- URLs / Query Params   (`URLTokenizer`)
- Logs / Security Feeds (`LogTokenizer`)

---

## ğŸ§© Key Features

- Formal definition of Ï„ (encode) and Îº (decode)
- Guaranteed reversibility: Îºâˆ˜Ï„ = Id
- Finite-State Transducer (FST) implementation
- K-best marginalization for stochastic consistency
- Hugging Face compatible export (tokenizer.json / vocab.txt)
- Consistency & Compression metrics

---

## ğŸ§ª Benchmarks

| Domain | Tokenizer | Consistency | Bits/Char | Encoding Speed |
|---------|------------|--------------|-------------|----------------|
| HTTP | WordPiece | 0.963 | 1.34 | 5100 tok/s |
| HTTP | BPE | 0.941 | 1.29 | 4900 tok/s |
| HTTP | **DST (ours)** | **1.000** | **1.17** | **6100 tok/s** |

---

## ğŸ“¦ Install

```bash
pip install domain-specific-tokenization
